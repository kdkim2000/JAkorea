{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lJqDOjW3gOS"
   },
   "source": [
    "# Pytorch로 딥러닝 제대로 배우기-중급\n",
    "## Part7-4: RNN 실습\n",
    "18개 언어로 구성된 단어 사전을 학습하여 주어진 단어가 어떤 언어인지 예측하는 모델 개발\n",
    "\n",
    "### 목차\n",
    "1. 데이터\n",
    "2. 모델\n",
    "3. 학습\n",
    "4. 모델 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWs5O0Lr398o"
   },
   "source": [
    "### (1) 데이터\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSLBZtSiPrvx"
   },
   "source": [
    "#### 데이터 다운로드\n",
    "\n",
    "본 데이터는 PyTorch 내부에서 다운로드가 불가능하기 때문에 외부에서 **다운**받아서 활용\n",
    "\n",
    "1. 다운로드 경로: [HERE](https://download.pytorch.org/tutorial/data.zip)\n",
    "2. 다운 받은 데이터를 압축 해제하여 Colab 디렉토리에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1671603610820,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "bU09XeiMQwxx",
    "outputId": "99ff498e-198f-4d78-c733-ae53e5213a60"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQe1p3ABRSHK"
   },
   "source": [
    "#### 데이터 준비\n",
    "1. 데이터를 파일로부터 읽어와서 Unicode string --> SSCII 변경\n",
    "2. Category(label)와 line(data)를 학습 데이터 구조화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1671603610820,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "xBeBee1kRQlR",
    "outputId": "5eaa2783-26a6-45a4-e03b-7d4427336b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('./dataset/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('./dataset/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines      # To make dataset\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8rKx826ShV_"
   },
   "source": [
    "#### Word to Vector Helper functions\n",
    "\n",
    "1. 알파벳을 one-hot 형태로 벡터화\n",
    "2. 단어를 텐서화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2062,
     "status": "ok",
     "timestamp": 1671603612881,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "BIKQDxWlSlBo",
    "outputId": "aa4cb728-c76a-42f0-fd70-8a4ef2b8417a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671603612882,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "xxOLTLghCZhB",
    "outputId": "bea4d658-8394-4b05-ab94-25fae223703b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(all_categories)\n",
    "print(category_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671603612882,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "XfRaWr9U8dDR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "  def __init__(self, category_lines):\n",
    "      self.x = []\n",
    "      self.y = []\n",
    "      for key, value in category_lines.items():\n",
    "        for line in value:\n",
    "          self.x.append(self.lineToTensor(line))\n",
    "          self.y.append(torch.tensor(all_categories.index(key), dtype=torch.long))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.y[idx]\n",
    "  \n",
    "  # Turn a line into a <line_length x 1 x n_letters>,\n",
    "  # or an array of one-hot letter vectors\n",
    "  def lineToTensor(self, line):\n",
    "      word2vec = []\n",
    "      for li, letter in enumerate(line):\n",
    "          tensor = torch.zeros(n_letters)\n",
    "          tensor[self.letterToIndex(letter)] = 1\n",
    "          word2vec.append(tensor)\n",
    "      return torch.stack(word2vec)\n",
    "  \n",
    "  # Find letter index from all_letters, e.g. \"a\" = 0\n",
    "  def letterToIndex(self, letter):\n",
    "      return all_letters.find(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1671603613221,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "3cw2iDQuLGoW"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m WordDataset(category_lines)\n\u001b[1;32m----> 2\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataset = WordDataset(category_lines)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sou4evfLSnwH"
   },
   "source": [
    "### (2) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4769,
     "status": "ok",
     "timestamp": 1671603618910,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "9beCKfEx3Z9m",
    "outputId": "191ec908-7a6f-4210-8884-452c85f924c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# CPU 또는 GPU 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(Net, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.rnn = nn.RNN(input_size=57, hidden_size=hidden_size)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  \n",
    "  def forward(self, input, hidden):\n",
    "    x = input.permute(1, 0, 2).contiguous()\n",
    "    out, h = self.rnn(x, hidden)\n",
    "    x = self.fc(out[-1])\n",
    "    return x, h\n",
    "  \n",
    "  def initHidden(self):\n",
    "    return torch.ones(1, 1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = Net(n_letters, n_hidden, n_categories).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjp35y9iTIkL"
   },
   "source": [
    "### (3) 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TQhjiQOTM14"
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671603618910,
     "user": {
      "displayName": "김동희",
      "userId": "01756196316806978263"
     },
     "user_tz": -540
    },
    "id": "hCx0Ra7lTjUA"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "  optim.zero_grad()\n",
    "  hidden = rnn.initHidden().to(device)\n",
    "  output, hidden = rnn(line_tensor, hidden)\n",
    "  loss = criterion(output, category_tensor)\n",
    "\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "\n",
    "  return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8Pn8ihg355O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:0 / Steps: 5000 / Accuracy: 0.359\n",
      "Epochs:0 / Steps: 10000 / Accuracy: 0.378\n",
      "Epochs:0 / Steps: 15000 / Accuracy: 0.381\n",
      "Epochs:0 / Steps: 20000 / Accuracy: 0.375\n",
      "Epochs:1 / Steps: 5000 / Accuracy: 0.356\n",
      "Epochs:1 / Steps: 10000 / Accuracy: 0.353\n",
      "Epochs:1 / Steps: 15000 / Accuracy: 0.349\n",
      "Epochs:1 / Steps: 20000 / Accuracy: 0.347\n",
      "Epochs:2 / Steps: 5000 / Accuracy: 0.365\n",
      "Epochs:2 / Steps: 10000 / Accuracy: 0.348\n",
      "Epochs:2 / Steps: 15000 / Accuracy: 0.348\n",
      "Epochs:2 / Steps: 20000 / Accuracy: 0.343\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "epochs = 5\n",
    "plot_every = 5000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(epochs):\n",
    "    step_counter = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      output, loss = train(x, y)\n",
    "      current_loss += loss\n",
    "      _, hat_y = output.max(1)\n",
    "      num_correct += (hat_y == y).sum()\n",
    "      step_counter += 1\n",
    "      if step_counter % plot_every == 0:\n",
    "          all_losses.append(current_loss / plot_every)\n",
    "          current_loss = 0\n",
    "          print(\"Epochs:{} / Steps: {} / Accuracy: {:.3f}\".format(i, \n",
    "                                                                  step_counter, \n",
    "                                                                  num_correct/step_counter))\n",
    "\n",
    "print(\"Time required: {}\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-AQ_fqMWHDT"
   },
   "source": [
    "#### Plotting run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBEyEHFIWKlr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcy1wB71a3Ew"
   },
   "source": [
    "### (4) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRI0s3Tza4x-"
   },
   "outputs": [],
   "source": [
    "class LSTM_Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(LSTM_Net, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(input_size=57, hidden_size=self.hidden_size)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  \n",
    "  def forward(self, input, hidden, cell):\n",
    "    x = input.permute(1, 0, 2).contiguous()\n",
    "    out, (h, c) = self.lstm(x, (hidden, cell))\n",
    "    x = self.fc(out[-1])\n",
    "    return x, h, c\n",
    "  \n",
    "  def initHidden(self):\n",
    "    return torch.ones(1, 1, self.hidden_size)\n",
    "  \n",
    "  def initCell(self):\n",
    "    return torch.ones(1, 1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "lstm = LSTM_Net(n_letters, n_hidden, n_categories).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K70i49QZblt6"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optim = torch.optim.Adam(lstm.parameters(), lr=0.01)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "    optim.zero_grad()\n",
    "    hidden = lstm.initHidden().to(device)\n",
    "    cell = lstm.initCell().to(device)\n",
    "\n",
    "    output, hidden, cell = lstm(line_tensor, hidden, cell)\n",
    "    loss = criterion(output, category_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Yksu7mbzgZ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "epochs = 5\n",
    "plot_every = 5000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(epochs):\n",
    "    step_counter = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      output, loss = train(x, y)\n",
    "      current_loss += loss\n",
    "      _, hat_y = output.max(1)\n",
    "      num_correct += (hat_y == y).sum()\n",
    "      step_counter += 1\n",
    "      if step_counter % plot_every == 0:\n",
    "          all_losses.append(current_loss / plot_every)\n",
    "          current_loss = 0\n",
    "          print(\"Epochs:{} / Steps: {} / Accuracy: {:.3f}\".format(i, \n",
    "                                                                  step_counter, \n",
    "                                                                  num_correct/step_counter))\n",
    "\n",
    "print(\"Time required: {}\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVPvZE-reLkC"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXUCeuB2eQa7"
   },
   "source": [
    "### (5) GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtpsajSpeTw9"
   },
   "outputs": [],
   "source": [
    "class GRU_Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(GRU_Net, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  \n",
    "  def forward(self, input, hidden):\n",
    "    x = input.permute(1, 0, 2).contiguous()\n",
    "    out, h = self.gru(x, hidden)\n",
    "    x = self.fc(out[-1])\n",
    "    return x, h\n",
    "  \n",
    "  def initHidden(self):\n",
    "    return torch.ones(1, 1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "gru = GRU_Net(n_letters, n_hidden, n_categories).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D80ytJZCel4Z"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(gru.parameters(), lr=0.01)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "    optim.zero_grad()\n",
    "    hidden = gru.initHidden().to(device)\n",
    "\n",
    "    output, hidden = gru(line_tensor, hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpFJKrqtewBu"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "epochs = 5\n",
    "plot_every = 5000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(epochs):\n",
    "    step_counter = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "      x = x.to(device) \n",
    "      y = y.to(device)\n",
    "      output, loss = train(x, y)\n",
    "      current_loss += loss\n",
    "      _, hat_y = output.max(1)\n",
    "      num_correct += (hat_y == y).sum()\n",
    "      step_counter += 1\n",
    "      if step_counter % plot_every == 0:\n",
    "          all_losses.append(current_loss / plot_every)\n",
    "          current_loss = 0\n",
    "          print(\"Epochs:{} / Steps: {} / Accuracy: {:.3f}\".format(i, \n",
    "                                                                  step_counter, \n",
    "                                                                  num_correct/step_counter))\n",
    "\n",
    "print(\"Time required: {}\".format(timeSince(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BQZhcxye0CG"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbbbieXpgooF2gRClSEG9g",
   "mount_file_id": "1B6yrM1EO75p__QCF2ZDLmx19FQytX8B6",
   "name": "",
   "provenance": [
    {
     "file_id": "1B6yrM1EO75p__QCF2ZDLmx19FQytX8B6",
     "timestamp": 1671598407525
    }
   ],
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
